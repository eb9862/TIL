# 결정계수($R^2$)

## 정의

결정계수 $R^2$는 회귀 모델이 얼마나 잘 데이터의 분산을 설명하는지 나타내는 지표입니다

즉, 실제값 $y$의 변동(variance)을 얼마나 많이 예측값 $\hat y$으로 설명할 수 있는지를 백분율 또는 비율로 표현합니다

## 계산 방식

$R^2 = \frac{\mathrm{ESS}}{\mathrm{TSS}} = 1 - \frac{\mathrm{RSS}}{\mathrm{TSS}}$

## 각 요소의 정의

### TSS (Total Sum of Squares, 총 제곱합)

$\mathrm{TSS} = \sum_{i=1}^n (y_i - \bar y)^2$

→ 실제 데이터 전체의 변동 정도 (평균으로부터의 차이)

### RSS (Residual Sum of Squares, 잔차 제곱합)

$\mathrm{RSS} = \sum_{i=1}^n (y_i - \hat y_i)^2
$  

→ 모델이 설명하지 못한 변동 (예측 오차의 제곱합)

### ESS (Explained Sum of Squares, 설명된 제곱합)

$\mathrm{ESS} = \sum_{i=1}^n (\hat y_i - \bar y)^2$  

→ 모델이 설명한 변동 (예측값이 평균으로부터 얼마나 벗어났는지)


### 관계식  

$\mathrm{TSS} = \mathrm{ESS} + \mathrm{RSS}$


## 해석

- $R^2 = 1$: 모델이 모든 변동을 설명 (완벽한 예측)  
- $R^2 = 0$: 모델이 단순히 평균값만 예측하는 수준  
- $R^2 < 0$: 모델이 평균 예측보다 못한 경우  
- 일반적으로 $0 \le R^2 \le 1$ 사이지만, 음수 가능  

## 한계 및 주의점

- 이상치(outlier)에 민감  
- 변수가 많아질수록 값이 인위적으로 커질 수 있음 → **조정된 결정계수 (Adjusted R²)** 사용 권장  
- 비선형 모델에서는 직관적 해석이 어렵거나 왜곡될 수 있음  
- 따라서 교차 검증 및 다른 지표(MAE, RMSE 등)와 병행해야 함

## 예시 코드 (Python)

```python
import numpy as np

def r2_score(y_true, y_pred):
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    y_mean = np.mean(y_true)
    rss = np.sum((y_true - y_pred)**2)               # 잔차 제곱합
    tss = np.sum((y_true - y_mean)**2)               # 총 제곱합
    ess = np.sum((y_pred - y_mean)**2)               # 설명된 제곱합
    return ess / tss   # 또는 1 - rss / tss
```

<br>

> 작성 - `2025.09.15`<br>
> 마지막 수정 - `2025.09.15`