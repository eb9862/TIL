# 특이값 분해 (Singular Value Decomposition, SVD)

특이값 분해(SVD)는 임의의 **실수 또는 복소수 행렬**을 세 개의 행렬로 분해하는 방법입니다

고유값 분해 정방행렬일 때만 가능하지만, 특이값 분해는 일반적인 행렬에 사용 가능합니다

이는 선형대수학에서 매우 중요한 기법으로, 차원 축소, 신호 처리, 추천 시스템 등 다양한 분야에서 활용됩니다

## 정의

임의의 \( m \times n \) 행렬 \( A \)가 있을 때, 특이값 분해는 다음과 같이 표현됩니다

$A = U \Sigma V^T$

- $A$: $m \times n$ 행렬
- $U$: $m \times m$ 직교 행렬 (좌특이벡터, orthogonal matrix)
- $\Sigma$: $m \times n$ 특이값으로 이루어진 대각 행렬
- $V$: $n \times n$ 직교 행렬 (우특이벡터, orthogonal matrix)

<img src="https://i.ibb.co/xtLHk1Hr/image.png" alt="image" border="0">

<br>

> **orthogonal matrix(직교 행렬)**<br>
> 행렬을 구성하는 행과 열 벡터들이 서로 수직을 이루고, 각 벡터의 크기가 1인 정사각형 행렬입니다.
> 정사각형 행렬 Q가 직교행렬이라는 것은 다음 조건들을 모두 만족한다는 의미입니다.<br>
> - 전치행렬이 역행렬과 같다
>   - $Q^T = Q^{−1}$ 
> - 행렬과 그 전치행렬의 곱이 단위행렬($I$)이다
>   - $Q^TQ = QQ^T =I$
> - 행렬의 모든 열(column) 벡터들이 서로 직교정규(orthonormal)하다
>   - 서로 직교(orthogonal) → 어떤 두 열 벡터를 뽑아 내적(dot product)해도 그 결과는 0입니다. (서로 수직)
>   - 크기가 1(normal): 각 열 벡터의 크기(norm)는 1입니다. (단위 벡터)
> - 행렬의 모든 행(row) 벡터들도 서로 직교정규하다

## 특이값과 특이벡터

#### 특이값(Singular Values)

- $\Sigma$의 대각 성분. 항상 **0 이상의 실수**입니다

- 보통 내림차순으로 정렬합니다

- $\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r > 0$

#### 좌특이벡터(Left Singular Vectors)

- 행렬 \( U \)의 열벡터, 
  $A v_i = \sigma_i u_i$

#### 우특이벡터(Right Singular Vectors)
  - 행렬 \( V \)의 열벡터, 
  $A^T u_i = \sigma_i v_i$

## 기하학적 의미

- 행렬 $A$는 단위 구를 **회전(직교변환)**시키고,  
  **축 방향으로 늘리거나 줄인 뒤**, 다시 **회전**시키는 변환으로 해석할 수 있습니다
- 즉,  
  1. $V^T$: 입력 벡터의 좌표계를 회전  
  2. $\Sigma$: 축 방향으로 스케일링  
  3. $U$: 출력 좌표계로 회전  

## 응용
1. **차원 축소 (PCA)**  
  데이터 행렬에 SVD를 적용하면, 가장 큰 특이값에 대응하는 특이벡터 방향이 데이터의 주성분이 됩니다

1. **추천 시스템 (Latent Semantic Analysis)**  
   사용자-아이템 행렬을 SVD로 분해해 잠재 요인을 추출합니다

2. **이미지 압축**  
   큰 특이값만 남기고 작은 특이값을 제거하면, 원래 행렬을 근사하면서 데이터 크기를 줄일 수 있습니다

3. **선형 방정식 해법**  
   역행렬이 존재하지 않는 경우(특히 비정방 행렬)에도, SVD를 이용하면 의사역행렬(pseudoinverse)을 계산해 근사 해를 구할 수 있습니다

<br>

> 참고자료 - [공돌이의 수학정리노트 (Angelo's Math Notes)](https://angeloyeo.github.io/2019/08/01/SVD.html)<br>
> 2025.09.11 작성