# 손실함수 (Loss Function)

## 정의
손실 함수(Loss Function)는 모델이 예측한 값과 실제 정답 값의 차이를 **수치적으로 평가**하는 함수입니다

즉, 예측이 실제에 얼마나 가까운지를 '실수'로 나타내는 지표라고 할 수 있고, 머신러닝 학습 시 **모델 파라미터**(가중치 등)을 조정하는 기준이 됩니다

## 역할

- 모델 학습 시 **손실(loss, error)** 을 최소화하는 방향으로 파라미터를 업데이트함으로써, 예측의 정확도를 개선함

- 다른 손실 함수를 쓰면 학습의 특성(오차에 대한 민감도, 이상치(outlier)에 대한 영향 등)이 달라짐

- 손실 값 자체는 학습 과정의 **진행도** (loss가 작아지는지 확인) 와 **최적화 비교** 에도 쓰임

## 주요 손실 함수들

### MAE (Mean Absolute Error)

- 정의
  - $\text{MAE} = \frac{1}{n} \sum_{i=1}^n \big| y_i - \hat y_i \big|$
- 특징
  - 절대값 사용 → 오차 크기에 비례한 선형적 패널티
  - 이상치(outlier)에 대해 MSE보다 덜 민감  
  - 미분이 절대값의 절단점(=0)에서 부드럽지 않은 점 있음

### MSE (Mean Squared Error)

- 정의
  - $\text{MSE} = \frac{1}{n} \sum_{i=1}^n (y_i - \hat y_i)^2$
- 특징
  - 제곱을 사용 → 큰 오차에 대해 매우 강한 페널티
  - 미분이 부드러움 → gradient 계산 시 해석적으로 간단
  - 이상치의 영향이 큼

### 교차 엔트로피 (Binary Cross-Entropy, 또는 Log Loss)

- 정의 (이진 분류 케이스)
  - $L = -\frac{1}{n} \sum_{i=1}^n \Big( y_i \log \hat y_i + (1 - y_i) \log(1 - \hat y_i) \Big)$  
  - 여기서 $\hat y_i$는 모델이 예측한 확률 (0~1)
- 특징  
  - 확률 기반 예측과 잘 어울림 (클래스 0 vs 클래스 1 확률)
  - 예측 확률이 실제 클래스와 멀면 손실이 급격히 커짐
  - 소프트맥스(다중 클래스) 또는 시그모이드 + BCEWithLogits 형태로 구현됨

## 정리

- 손실 함수 선택은 **문제 종류**(회귀 vs 분류), **데이터 특성**(이상치 존재 여부), **추론 방식**(확률 예측 여부) 등에 따라 달라짐  
- 회귀 문제엔 보통 MAE 또는 MSE, 분류 문제엔 (Binary) Cross-Entropy가 많이 쓰임  
- 모델의 학습 안정성, 수렴 속도, 최종 성능을 모두 고려해서 손실 함수를 선택하는 것이 중요함

> 작성 - `2025.09.15`<br>
> 마지막 수정 - `2025.09.15`